<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Recommendations | AI Model Guide</title>
    <meta name="description" content="A practical guide to understanding and using modern AI models.">
    <meta name="generator" content="VitePress v2.0.0-alpha.12">
    <link rel="preload stylesheet" href="/vitepress-llm-recommends/assets/style.DQ7kH3JY.css" as="style">
    <link rel="preload stylesheet" href="/vitepress-llm-recommends/vp-icons.css" as="style">
    
    <script type="module" src="/vitepress-llm-recommends/assets/app.IP3h1B2O.js"></script>
    <link rel="preload" href="/vitepress-llm-recommends/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/vitepress-llm-recommends/assets/chunks/theme.BbyOaCFE.js">
    <link rel="modulepreload" href="/vitepress-llm-recommends/assets/chunks/framework.CuQK53I8.js">
    <link rel="modulepreload" href="/vitepress-llm-recommends/assets/recommendations_index.md.CG7jtKFJ.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-1df9f90f><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-1df9f90f data-v-9f75dce3><div class="VPNavBar" data-v-9f75dce3 data-v-2a96a3d0><div class="wrapper" data-v-2a96a3d0><div class="container" data-v-2a96a3d0><div class="title" data-v-2a96a3d0><div class="VPNavBarTitle has-sidebar" data-v-2a96a3d0 data-v-1e38c6bc><a class="title" href="/vitepress-llm-recommends/" data-v-1e38c6bc><!--[--><!--]--><!----><span data-v-1e38c6bc>AI Model Guide</span><!--[--><!--]--></a></div></div><div class="content" data-v-2a96a3d0><div class="content-body" data-v-2a96a3d0><!--[--><!--]--><div class="VPNavBarSearch search" data-v-2a96a3d0><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-2a96a3d0 data-v-39714824><span id="main-nav-aria-label" class="visually-hidden" data-v-39714824> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/evaluation/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Evaluation</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/inference/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Inference</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/model-types/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Model Types</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink active" href="/vitepress-llm-recommends/recommendations/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Recommendations</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-2a96a3d0 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-2a96a3d0 data-v-0394ad82 data-v-d07f11e6><!--[--><a class="VPSocialLink no-icon" href="https://github.com/MaxKruse/vitepress-llm-recommends/" aria-label="github" target="_blank" rel="me noopener" data-v-d07f11e6 data-v-591a6b30><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-2a96a3d0 data-v-bb2aa2f0 data-v-42cb505d><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-42cb505d><span class="vpi-more-horizontal icon" data-v-42cb505d></span></button><div class="menu" data-v-42cb505d><div class="VPMenu" data-v-42cb505d data-v-25a6cce8><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-d07f11e6><!--[--><a class="VPSocialLink no-icon" href="https://github.com/MaxKruse/vitepress-llm-recommends/" aria-label="github" target="_blank" rel="me noopener" data-v-d07f11e6 data-v-591a6b30><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-2a96a3d0 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-2a96a3d0><div class="divider-line" data-v-2a96a3d0></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-1df9f90f data-v-8acdfeb5><div class="container" data-v-8acdfeb5><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-8acdfeb5><span class="vpi-align-left menu-icon" data-v-8acdfeb5></span><span class="menu-text" data-v-8acdfeb5>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-8acdfeb5 data-v-0bf0e06f><button data-v-0bf0e06f>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-1df9f90f data-v-e7c6e512><div class="curtain" data-v-e7c6e512></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-e7c6e512><span class="visually-hidden" id="sidebar-aria-label" data-v-e7c6e512> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Introduction</h2><!----></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Home</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Evaluation</h2><!----></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/evaluation/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Inference</h2><!----></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/inference/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0 collapsible" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Model Types</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-d81de50c><span class="vpi-chevron-right caret-icon" data-v-d81de50c></span></div></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/model-types/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/model-types/dense/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Dense Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/model-types/mixture-of-experts/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Mixture of Experts (MoE)</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0 collapsible has-active" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Recommendations</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-d81de50c><span class="vpi-chevron-right caret-icon" data-v-d81de50c></span></div></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/coding/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Coding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/instruct/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Instruct-Tuned</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/personal-assistant/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Personal Assistant</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/stem/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>STEM</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/storywriting/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Storywriting</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-1df9f90f data-v-aff0b8d7><div class="VPDoc has-sidebar has-aside" data-v-aff0b8d7 data-v-7011f0d8><!--[--><!--]--><div class="container" data-v-7011f0d8><div class="aside" data-v-7011f0d8><div class="aside-curtain" data-v-7011f0d8></div><div class="aside-container" data-v-7011f0d8><div class="aside-content" data-v-7011f0d8><div class="VPDocAside" data-v-7011f0d8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-60d5052e><div class="content" data-v-60d5052e><div class="outline-marker" data-v-60d5052e></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-60d5052e>On this page</div><ul class="VPDocOutlineItem root" data-v-60d5052e data-v-2d0bdf9b><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-7011f0d8><div class="content-container" data-v-7011f0d8><!--[--><!--]--><main class="main" data-v-7011f0d8><div style="position:relative;" class="vp-doc _vitepress-llm-recommends_recommendations_" data-v-7011f0d8><div><h1 id="recommendations" tabindex="-1">Recommendations <a class="header-anchor" href="#recommendations" aria-label="Permalink to “Recommendations”">​</a></h1><p>Choose the right model and hardware setup based on your specific use case. Below are tailored guides for common scenarios:</p><ul><li><p><a href="./coding/"><strong>Coding Assistants</strong></a><br> Models and hardware for code generation, autocomplete, and debugging.</p></li><li><p><a href="./instruct/"><strong>Instruction-Following Tasks</strong></a><br> Best choices for chatbots, customer support, and general-purpose assistants.</p></li><li><p><a href="./personal-assistant/"><strong>Personal AI Assistants</strong></a><br> Optimized setups for private, responsive, and context-aware daily use.</p></li><li><p><a href="./stem/"><strong>STEM &amp; Technical Reasoning</strong></a><br> Models with strong math, logic, and scientific reasoning capabilities.</p></li><li><p><a href="./storywriting/"><strong>Creative Storywriting</strong></a><br> Architectures and configurations for long-form, coherent, and imaginative text.</p></li></ul><p>Each guide includes model suggestions, quantization tips, and minimum/recommended hardware specs.</p><h2 id="parameters-quantization-and-hallucinations" tabindex="-1">Parameters, Quantization, and Hallucinations <a class="header-anchor" href="#parameters-quantization-and-hallucinations" aria-label="Permalink to “Parameters, Quantization, and Hallucinations”">​</a></h2><p>This section explores the core concepts you&#39;ll encounter when working with local LLMs: parameters, quantization, and hallucinations.</p><h3 id="what-are-parameters" tabindex="-1">What are Parameters? <a class="header-anchor" href="#what-are-parameters" aria-label="Permalink to “What are Parameters?”">​</a></h3><p>In an LLM, <strong>parameters</strong> are the internal variables the model learns during training. Think of them as the neurons and the connections between them. The number of parameters determines the model&#39;s capacity to store and process information.</p><ul><li><strong>Model Size</strong>: Modern models typically become useful out-of-the-box starting around 1-4 billion (B) parameters.</li><li><strong>Data Precision</strong>: Most models are initially trained in <strong>FP16</strong> (16-bit floating point), meaning each parameter can hold 16 bits of information.</li></ul><p>The more parameters a model has, the more potential space there is for information to be learned without &quot;overwriting&quot; previously learned knowledge.</p><h4 id="the-role-of-training" tabindex="-1">The Role of Training <a class="header-anchor" href="#the-role-of-training" aria-label="Permalink to “The Role of Training”">​</a></h4><p>Sadly, as of late 2025, most consumer-level LLMs are heavily undertrained. This becomes evident when we apply quantization (explained below).</p><p>To put it simply: if there are 16 bits of space available in a parameter, but on average, only 4 of those bits are effectively used during training, the other 12 bits contribute very little to the final output quality. This is why you&#39;ll often see recommendations for extreme quantization methods like <strong>Q4</strong> (an average of 4 bits per parameter) or even lower.</p><p>To illustrate the relationship between model size, training, and quantization:</p><p>Imagine we take a 4B model and a 70B model from the same family.</p><ol><li>We train both on the exact same data for the same number of iterations.</li><li>The smaller 4B model might become &quot;full,&quot; saturating most of the 16 bits in its 4 billion parameters.</li><li>The larger 70B model, with its vast capacity, might only effectively use, let&#39;s say, 8 bits of information per parameter on average.</li></ol><p>Now, if we quantize both models to <strong>Q4</strong>:</p><ul><li>The 4B model loses a significant amount of its learned data (going from ~16 bits to 4 bits).</li><li>The 70B model is less affected because it was only using ~8 bits of information anyway. Its perceived quality drop is much smaller.</li></ul><p>This is why quantizing a massive, undertrained 70B model to Q4 is often less of an issue than quantizing an 8B model of the same family, or comparing it to better-trained models like the <strong>Qwen3 Family (which is NOT undertrained and utilizes all 16 bits very effectively)</strong>.</p><h3 id="what-is-quantization" tabindex="-1">What is Quantization? <a class="header-anchor" href="#what-is-quantization" aria-label="Permalink to “What is Quantization?”">​</a></h3><p>Quantization is the process of reducing the precision of a model&#39;s parameters to save memory and improve performance.</p><p>Imagine a single 16-bit parameter (<code>0011010101110101</code>) represents the following detailed information:</p><blockquote><p>Leaves appear green because of chlorophyll, a pigment found inside plant cells (specifically in chloroplasts). Chlorophyll plays a critical role in photosynthesis, the process plants use to convert light energy into chemical energy.</p><p>Sunlight contains all wavelengths (colors) of visible light. Chlorophyll absorbs light most efficiently in the blue (~430-450 nm) and red (~640-680 nm) regions of the spectrum, which are used to drive photosynthesis.</p><p>However, it reflects and transmits green light (~500-550 nm) rather than absorbing it. Because the green wavelengths are not absorbed, they bounce off the leaf and enter our eyes — that&#39;s why we perceive leaves as green.</p></blockquote><p>If we quantize this 16-bit value down to just 4 bits (<code>0011</code>), we are essentially &quot;cutting off&quot; the fine-grained details. The model might now only retain enough information to generate a simpler explanation:</p><blockquote><p>Leaves are green because they have a special color helper inside called chlorophyll.</p><p>The leaf uses sunlight to make its food, kind of like how you eat to get energy. Chlorophyll drinks up red and blue sunlight but doesn&#39;t like green light — it bounces the green light away.</p><p>That&#39;s what your eyes see, so the leaf looks green!</p></blockquote><p>By removing detail, you risk losing accuracy. While the quantized model still seems to understand the core concept, it has lost nuance and is more likely to make mistakes or hallucinate.</p><h3 id="what-are-hallucinations" tabindex="-1">What are Hallucinations? <a class="header-anchor" href="#what-are-hallucinations" aria-label="Permalink to “What are Hallucinations?”">​</a></h3><p>LLMs famously &quot;hallucinate&quot;—they generate confident-sounding but incorrect or nonsensical information. While the exact cause is complex, you can think of it like this:</p><p>Imagine you know many different topics, but only at a very surface level. If someone asks you a question that <em>seems</em> like it could be answered by combining facts from different topics, you might construct an answer that sounds plausible but is ultimately wrong.</p><p>Consider an LLM that has learned the following isolated facts:</p><ol><li>Streets are clean because the city pays for cleaning them.</li><li>Your house is clean because your parents clean it from time to time.</li><li>The local McDonald&#39;s is never clean because the workers are too busy.</li></ol><p>If you ask the LLM, &quot;Why is my house not clean?&quot; it might correctly infer, &quot;Because your parents are busy.&quot;</p><p>However, it could also incorrectly combine unrelated facts and produce a hallucination:</p><blockquote><p>&quot;Your house is not clean because the city is not paying your parents.&quot;</p></blockquote><h1 id="sources" tabindex="-1">Sources <a class="header-anchor" href="#sources" aria-label="Permalink to “Sources”">​</a></h1><ul><li><strong><a href="https://www.ibm.com/think/topics/llm-parameters/" target="_blank" rel="noreferrer">Parameters</a></strong></li><li><strong><a href="https://www.datacamp.com/tutorial/quantization-for-large-language-models/" target="_blank" rel="noreferrer">Quantization</a></strong></li><li><strong><a href="https://openai.com/index/why-language-models-hallucinate/" target="_blank" rel="noreferrer">Hallucinations</a></strong></li></ul></div></div></main><footer class="VPDocFooter" data-v-7011f0d8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/vitepress-llm-recommends/model-types/mixture-of-experts/" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Previous page</span><span class="title" data-v-e257564d>Mixture of Experts (MoE)</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/vitepress-llm-recommends/recommendations/coding/" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>Coding</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-1df9f90f data-v-c3855bb3><div class="container" data-v-c3855bb3><p class="message" data-v-c3855bb3>Released under the MIT License.</p><p class="copyright" data-v-c3855bb3>Copyright © 2025 Maximilian Kruse</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"evaluation_index.md\":\"C14o8Jc1\",\"index.md\":\"Ub8Qo3-D\",\"inference_index.md\":\"BwcfjRLF\",\"model-types_dense_index.md\":\"CbxFSXIU\",\"model-types_index.md\":\"DN1SIc1e\",\"model-types_mixture-of-experts_index.md\":\"Dup0hR6-\",\"recommendations_coding_index.md\":\"Cq2-M354\",\"recommendations_index.md\":\"CG7jtKFJ\",\"recommendations_instruct_index.md\":\"no7KdZb7\",\"recommendations_personal-assistant_index.md\":\"VwTtcm-U\",\"recommendations_stem_index.md\":\"Dglu-95U\",\"recommendations_storywriting_index.md\":\"rPXxyZGZ\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"AI Model Guide\",\"description\":\"A practical guide to understanding and using modern AI models.\",\"base\":\"/vitepress-llm-recommends/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Evaluation\",\"link\":\"/evaluation/\"},{\"text\":\"Inference\",\"link\":\"/inference/\"},{\"text\":\"Model Types\",\"link\":\"/model-types/\"},{\"text\":\"Recommendations\",\"link\":\"/recommendations/\"}],\"sidebar\":[{\"text\":\"Introduction\",\"items\":[{\"text\":\"Home\",\"link\":\"/\"}]},{\"text\":\"Evaluation\",\"items\":[{\"text\":\"Overview\",\"link\":\"/evaluation/\"}]},{\"text\":\"Inference\",\"items\":[{\"text\":\"Overview\",\"link\":\"/inference/\"}]},{\"text\":\"Model Types\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/model-types/\"},{\"text\":\"Dense Models\",\"link\":\"/model-types/dense/\"},{\"text\":\"Mixture of Experts (MoE)\",\"link\":\"/model-types/mixture-of-experts/\"}]},{\"text\":\"Recommendations\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/recommendations/\"},{\"text\":\"Coding\",\"link\":\"/recommendations/coding/\"},{\"text\":\"Instruct-Tuned\",\"link\":\"/recommendations/instruct/\"},{\"text\":\"Personal Assistant\",\"link\":\"/recommendations/personal-assistant/\"},{\"text\":\"STEM\",\"link\":\"/recommendations/stem/\"},{\"text\":\"Storywriting\",\"link\":\"/recommendations/storywriting/\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/MaxKruse/vitepress-llm-recommends/\"}],\"footer\":{\"message\":\"Released under the MIT License.\",\"copyright\":\"Copyright © 2025 Maximilian Kruse\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false,\"additionalConfig\":{}}");</script>
    
  </body>
</html>