<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Personal Assistant | AI Model Guide</title>
    <meta name="description" content="A practical guide to understanding and using modern AI models.">
    <meta name="generator" content="VitePress v2.0.0-alpha.12">
    <link rel="preload stylesheet" href="/vitepress-llm-recommends/assets/style.lLZuWYqG.css" as="style">
    <link rel="preload stylesheet" href="/vitepress-llm-recommends/vp-icons.css" as="style">
    
    <script type="module" src="/vitepress-llm-recommends/assets/app.CxDjSkIe.js"></script>
    <link rel="preload" href="/vitepress-llm-recommends/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/vitepress-llm-recommends/assets/chunks/theme.WU6Zdw17.js">
    <link rel="modulepreload" href="/vitepress-llm-recommends/assets/chunks/framework.t7omRjYa.js">
    <link rel="modulepreload" href="/vitepress-llm-recommends/assets/recommendations_personal-assistant_index.md.Dx2cmzmy.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-1df9f90f><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-1df9f90f data-v-9f75dce3><div class="VPNavBar" data-v-9f75dce3 data-v-2a96a3d0><div class="wrapper" data-v-2a96a3d0><div class="container" data-v-2a96a3d0><div class="title" data-v-2a96a3d0><div class="VPNavBarTitle has-sidebar" data-v-2a96a3d0 data-v-1e38c6bc><a class="title" href="/vitepress-llm-recommends/" data-v-1e38c6bc><!--[--><!--]--><!----><span data-v-1e38c6bc>AI Model Guide</span><!--[--><!--]--></a></div></div><div class="content" data-v-2a96a3d0><div class="content-body" data-v-2a96a3d0><!--[--><!--]--><div class="VPNavBarSearch search" data-v-2a96a3d0><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-2a96a3d0 data-v-39714824><span id="main-nav-aria-label" class="visually-hidden" data-v-39714824> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/evaluation/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Evaluation</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/inference/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Inference</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/model-types/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Model Types</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/recommendations/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Recommendations</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-2a96a3d0 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-2a96a3d0 data-v-0394ad82 data-v-d07f11e6><!--[--><a class="VPSocialLink no-icon" href="https://github.com/MaxKruse/vitepress-llm-recommends/" aria-label="github" target="_blank" rel="me noopener" data-v-d07f11e6 data-v-591a6b30><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-2a96a3d0 data-v-bb2aa2f0 data-v-42cb505d><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-42cb505d><span class="vpi-more-horizontal icon" data-v-42cb505d></span></button><div class="menu" data-v-42cb505d><div class="VPMenu" data-v-42cb505d data-v-25a6cce8><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-d07f11e6><!--[--><a class="VPSocialLink no-icon" href="https://github.com/MaxKruse/vitepress-llm-recommends/" aria-label="github" target="_blank" rel="me noopener" data-v-d07f11e6 data-v-591a6b30><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-2a96a3d0 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-2a96a3d0><div class="divider-line" data-v-2a96a3d0></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-1df9f90f data-v-8acdfeb5><div class="container" data-v-8acdfeb5><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-8acdfeb5><span class="vpi-align-left menu-icon" data-v-8acdfeb5></span><span class="menu-text" data-v-8acdfeb5>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-8acdfeb5 data-v-0bf0e06f><button data-v-0bf0e06f>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-1df9f90f data-v-e7c6e512><div class="curtain" data-v-e7c6e512></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-e7c6e512><span class="visually-hidden" id="sidebar-aria-label" data-v-e7c6e512> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Introduction</h2><!----></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Home</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Evaluation</h2><!----></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/evaluation/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Inference</h2><!----></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/inference/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0 collapsible" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Model Types</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-d81de50c><span class="vpi-chevron-right caret-icon" data-v-d81de50c></span></div></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/model-types/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/model-types/dense/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Dense Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/model-types/mixture-of-experts/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Mixture of Experts (MoE)</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0 collapsible has-active" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Recommendations</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-d81de50c><span class="vpi-chevron-right caret-icon" data-v-d81de50c></span></div></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/coding/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Coding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/instruct/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Instruct-Tuned</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/personal-assistant/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Personal Assistant</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/stem/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>STEM</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/storywriting/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Storywriting</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-1df9f90f data-v-aff0b8d7><div class="VPDoc has-sidebar has-aside" data-v-aff0b8d7 data-v-7011f0d8><!--[--><!--]--><div class="container" data-v-7011f0d8><div class="aside" data-v-7011f0d8><div class="aside-curtain" data-v-7011f0d8></div><div class="aside-container" data-v-7011f0d8><div class="aside-content" data-v-7011f0d8><div class="VPDocAside" data-v-7011f0d8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-60d5052e><div class="content" data-v-60d5052e><div class="outline-marker" data-v-60d5052e></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-60d5052e>On this page</div><ul class="VPDocOutlineItem root" data-v-60d5052e data-v-2d0bdf9b><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-7011f0d8><div class="content-container" data-v-7011f0d8><!--[--><!--]--><main class="main" data-v-7011f0d8><div style="position:relative;" class="vp-doc _vitepress-llm-recommends_recommendations_personal-assistant_" data-v-7011f0d8><div data-v-51815719><h1 id="personal-assistant-use-case" tabindex="-1" data-v-51815719>Personal Assistant Use Case <a class="header-anchor" href="#personal-assistant-use-case" aria-label="Permalink to “Personal Assistant Use Case”" data-v-51815719>​</a></h1><p data-v-51815719>Recommendations for models that excel at memory, context retention, and personalized interactions.</p><blockquote data-v-51815719><p data-v-51815719>💡 <strong data-v-51815719>Note</strong>: For personal assistant tasks—such as recalling preferences, maintaining conversation history, managing schedules, or adapting tone over time—<strong data-v-51815719>instruct-tuned models with strong long-context handling</strong> are preferred over thinking-tuned variants. These models prioritize coherence, empathy, and user-specific adaptation over raw analytical power.</p></blockquote><p data-v-51815719>Use the selector below to find the best <strong data-v-51815719>assistant-like</strong> model for your hardware:</p><div class="recommended-warning model-selector" data-v-51815719><div class="controls" data-v-51815719><div class="control-group" data-v-51815719><label for="ram-select" data-v-51815719>RAM (GB)</label><select id="ram-select" data-v-51815719><!--[--><option value="16" data-v-51815719 selected>16</option><option value="32" data-v-51815719>32</option><option value="64" data-v-51815719>64</option><option value="128" data-v-51815719>128</option><!--]--></select></div><div class="control-group" data-v-51815719><label for="vram-select" data-v-51815719>VRAM (GB)</label><select id="vram-select" data-v-51815719><!--[--><option value="0" data-v-51815719>0</option><option value="4" data-v-51815719>4</option><option value="6" data-v-51815719>6</option><option value="8" data-v-51815719 selected>8</option><option value="12" data-v-51815719>12</option><option value="16" data-v-51815719>16</option><option value="24" data-v-51815719>24</option><option value="32" data-v-51815719>32</option><!--]--></select></div></div><div class="result" data-v-51815719><strong data-v-51815719>Recommended model:</strong><span class="recommended-warning model-name" style="background-color:var(--vp-c-orange-soft);color:var(--vp-c-orange-2);" data-v-51815719>Gemma 3 12B Q4</span></div></div><blockquote data-v-51815719><p data-v-51815719><strong data-v-51815719>“Not recommended” means poor conversational memory and unreliable personalization</strong> On under-resourced systems, models may forget prior context within a few exchanges or fail to maintain consistent user preferences—making them ineffective as true personal assistants.</p></blockquote><hr data-v-51815719><h2 id="how-to-use-instruct-tuned-models-as-a-personal-assistant" tabindex="-1" data-v-51815719>How to Use Instruct-Tuned Models as a Personal Assistant <a class="header-anchor" href="#how-to-use-instruct-tuned-models-as-a-personal-assistant" aria-label="Permalink to “How to Use Instruct-Tuned Models as a Personal Assistant”" data-v-51815719>​</a></h2><p data-v-51815719>Personal assistant models thrive on <strong data-v-51815719>long-term context awareness</strong>, <strong data-v-51815719>empathetic tone</strong>, and <strong data-v-51815719>user-specific adaptation</strong>. These prioritize natural dialogue, recall simulation, and task coordination.</p><h3 id="_1-choose-instruct-tuned-models" tabindex="-1" data-v-51815719>1. <strong data-v-51815719>Choose Instruct-Tuned Models</strong> <a class="header-anchor" href="#_1-choose-instruct-tuned-models" aria-label="Permalink to “1. Choose Instruct-Tuned Models”" data-v-51815719>​</a></h3><ul data-v-51815719><li data-v-51815719>Use <strong data-v-51815719><code data-v-51815719>instruct</code></strong> variants (e.g., <code data-v-51815719>qwen3 4b instruct</code>, <code data-v-51815719>gpt-oss 20b</code>)—they&#39;re fine-tuned for: <ul data-v-51815719><li data-v-51815719>Following multi-turn instructions</li><li data-v-51815719>Remembering stated preferences (“I prefer morning summaries”)</li><li data-v-51815719>Managing to-do lists, reminders, or journaling prompts</li><li data-v-51815719>Adapting tone (casual, professional, supportive)</li></ul></li><li data-v-51815719>Avoid <code data-v-51815719>thinking</code> models—they may over-analyze simple requests or ignore emotional nuance.</li></ul><h3 id="_2-prioritize-context-length-quantization" tabindex="-1" data-v-51815719>2. <strong data-v-51815719>Prioritize Context Length &amp; Quantization</strong> <a class="header-anchor" href="#_2-prioritize-context-length-quantization" aria-label="Permalink to “2. Prioritize Context Length &amp; Quantization”" data-v-51815719>​</a></h3><table tabindex="0" data-v-51815719><thead data-v-51815719><tr data-v-51815719><th data-v-51815719>Quant</th><th data-v-51815719>Assistant Impact</th></tr></thead><tbody data-v-51815719><tr data-v-51815719><td data-v-51815719><code data-v-51815719>bf16</code> / <code data-v-51815719>f16</code></td><td data-v-51815719>Best for full personality retention over long chats; ideal if you use 32K+ context</td></tr><tr data-v-51815719><td data-v-51815719><code data-v-51815719>q8</code></td><td data-v-51815719>Excellent balance—retains nuance while fitting in moderate VRAM</td></tr><tr data-v-51815719><td data-v-51815719><code data-v-51815719>q6</code> / <code data-v-51815719>q4</code></td><td data-v-51815719>Usable for basic tasks, but may “forget” early conversation details in long sessions</td></tr></tbody></table><blockquote data-v-51815719><p data-v-51815719>🔹 <strong data-v-51815719>Tip</strong>: For personal assistants, <strong data-v-51815719>context length matters more than raw parameter count</strong>. A well-quantized 20B model with 32K context often outperforms a 30B model limited to 4K.</p></blockquote><h3 id="_3-enable-full-gpu-offload" tabindex="-1" data-v-51815719>3. <strong data-v-51815719>Enable Full GPU Offload</strong> <a class="header-anchor" href="#_3-enable-full-gpu-offload" aria-label="Permalink to “3. Enable Full GPU Offload”" data-v-51815719>​</a></h3><ul data-v-51815719><li data-v-51815719>Always use <strong data-v-51815719>full GPU offload</strong> (e.g., 48/48 layers) in LM Studio to keep conversation fast and responsive.</li><li data-v-51815719>If LM Studio pre-selects offload settings for your model, <strong data-v-51815719>do not override them</strong>.</li></ul><h3 id="_4-simulate-memory-with-prompt-engineering" tabindex="-1" data-v-51815719>4. <strong data-v-51815719>Simulate Memory with Prompt Engineering</strong> <a class="header-anchor" href="#_4-simulate-memory-with-prompt-engineering" aria-label="Permalink to “4. Simulate Memory with Prompt Engineering”" data-v-51815719>​</a></h3><p data-v-51815719>Since local models lack true persistent memory:</p><ul data-v-51815719><li data-v-51815719><strong data-v-51815719>Seed your prompt</strong> with key facts:<div class="language-text" data-v-51815719><button title="Copy Code" class="copy" data-v-51815719></button><span class="lang" data-v-51815719>text</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr" data-v-51815719><code data-v-51815719><span class="line" data-v-51815719><span data-v-51815719>You are my personal assistant. I&#39;m a developer who enjoys Blender 3D. I eat meals regularly and track my learning goals. Today is Thursday, October 23, 2025.</span></span></code></pre></div></li><li data-v-51815719>Use <strong data-v-51815719>structured recall cues</strong>: <ul data-v-51815719><li data-v-51815719>“Based on our last conversation about Blender shaders…”</li><li data-v-51815719>“Remind me of my food preferences before suggesting dinner ideas.”</li></ul></li></ul><h3 id="_5-avoid-none-configurations" tabindex="-1" data-v-51815719>5. <strong data-v-51815719>Avoid “None” Configurations</strong> <a class="header-anchor" href="#_5-avoid-none-configurations" aria-label="Permalink to “5. Avoid “None” Configurations”" data-v-51815719>​</a></h3><ul data-v-51815719><li data-v-51815719>Systems returning “none” lack the capacity to maintain even short-term conversational state.</li><li data-v-51815719>Forcing a load via CPU offload leads to: <ul data-v-51815719><li data-v-51815719>Slow responses that break conversational flow</li></ul></li><li data-v-51815719><strong data-v-51815719>Minimum viable setup</strong>: ≥6 GB VRAM + <code data-v-51815719>qwen3 4b instruct q4</code> for basic assistant duties.</li></ul><h3 id="_6-combine-with-external-memory-advanced" tabindex="-1" data-v-51815719>6. <strong data-v-51815719>Combine with External Memory (Advanced)</strong> <a class="header-anchor" href="#_6-combine-with-external-memory-advanced" aria-label="Permalink to “6. Combine with External Memory (Advanced)”" data-v-51815719>​</a></h3><p data-v-51815719>For true long-term memory:</p><ul data-v-51815719><li data-v-51815719>Log key interactions to a local file or database</li><li data-v-51815719>Inject summarized memory into each new session:<div class="language-text" data-v-51815719><button title="Copy Code" class="copy" data-v-51815719></button><span class="lang" data-v-51815719>text</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr" data-v-51815719><code data-v-51815719><span class="line" data-v-51815719><span data-v-51815719>[Memory Summary: User is learning Blender geometry nodes. Last discussed procedural terrain generation on Oct 20. Prefers vegetarian meal suggestions.]</span></span></code></pre></div></li><li data-v-51815719>This turns even a 4B model into a surprisingly capable companion.</li></ul><h3 id="_7-monitor-resource-usage" tabindex="-1" data-v-51815719>7. <strong data-v-51815719>Monitor Resource Usage</strong> <a class="header-anchor" href="#_7-monitor-resource-usage" aria-label="Permalink to “7. Monitor Resource Usage”" data-v-51815719>​</a></h3><ul data-v-51815719><li data-v-51815719>Keep VRAM usage <strong data-v-51815719>below 90%</strong> to avoid swapping, which destroys real-time responsiveness.</li><li data-v-51815719>On Windows, disable background apps (Discord, browsers) to free up the extra 1-2 GB needed for smooth 16K context.</li></ul><hr data-v-51815719><p data-v-51815719>By selecting the right instruct-tuned model for your hardware and structuring interactions to simulate memory, you can create a <strong data-v-51815719>responsive, personalized, and helpful local AI assistant</strong>—without relying on cloud services or sacrificing privacy.</p></div></div></main><footer class="VPDocFooter" data-v-7011f0d8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/vitepress-llm-recommends/recommendations/instruct/" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Previous page</span><span class="title" data-v-e257564d>Instruct-Tuned</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/vitepress-llm-recommends/recommendations/stem/" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>STEM</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-1df9f90f data-v-c3855bb3><div class="container" data-v-c3855bb3><p class="message" data-v-c3855bb3>Released under the MIT License.</p><p class="copyright" data-v-c3855bb3>Copyright © 2025 Maximilian Kruse</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"evaluation_index.md\":\"CQaje612\",\"index.md\":\"D0wSj2Q9\",\"inference_index.md\":\"Dgy3BO6N\",\"model-types_dense_index.md\":\"CnOwRW-4\",\"model-types_index.md\":\"DNOmDuiS\",\"model-types_mixture-of-experts_index.md\":\"jQ3fok6t\",\"recommendations_coding_index.md\":\"CamW7-ON\",\"recommendations_index.md\":\"CBvKaARS\",\"recommendations_instruct_index.md\":\"BmSBpx3Q\",\"recommendations_personal-assistant_index.md\":\"Dx2cmzmy\",\"recommendations_stem_index.md\":\"C_Dam5SV\",\"recommendations_storywriting_index.md\":\"CJ0SsmA6\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"AI Model Guide\",\"description\":\"A practical guide to understanding and using modern AI models.\",\"base\":\"/vitepress-llm-recommends/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Evaluation\",\"link\":\"/evaluation/\"},{\"text\":\"Inference\",\"link\":\"/inference/\"},{\"text\":\"Model Types\",\"link\":\"/model-types/\"},{\"text\":\"Recommendations\",\"link\":\"/recommendations/\"}],\"sidebar\":[{\"text\":\"Introduction\",\"items\":[{\"text\":\"Home\",\"link\":\"/\"}]},{\"text\":\"Evaluation\",\"items\":[{\"text\":\"Overview\",\"link\":\"/evaluation/\"}]},{\"text\":\"Inference\",\"items\":[{\"text\":\"Overview\",\"link\":\"/inference/\"}]},{\"text\":\"Model Types\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/model-types/\"},{\"text\":\"Dense Models\",\"link\":\"/model-types/dense/\"},{\"text\":\"Mixture of Experts (MoE)\",\"link\":\"/model-types/mixture-of-experts/\"}]},{\"text\":\"Recommendations\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/recommendations/\"},{\"text\":\"Coding\",\"link\":\"/recommendations/coding/\"},{\"text\":\"Instruct-Tuned\",\"link\":\"/recommendations/instruct/\"},{\"text\":\"Personal Assistant\",\"link\":\"/recommendations/personal-assistant/\"},{\"text\":\"STEM\",\"link\":\"/recommendations/stem/\"},{\"text\":\"Storywriting\",\"link\":\"/recommendations/storywriting/\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/MaxKruse/vitepress-llm-recommends/\"}],\"footer\":{\"message\":\"Released under the MIT License.\",\"copyright\":\"Copyright © 2025 Maximilian Kruse\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false,\"additionalConfig\":{}}");</script>
    
  </body>
</html>