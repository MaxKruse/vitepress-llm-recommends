<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>STEM | AI Model Guide</title>
    <meta name="description" content="A practical guide to understanding and using modern AI models.">
    <meta name="generator" content="VitePress v2.0.0-alpha.12">
    <link rel="preload stylesheet" href="/vitepress-llm-recommends/assets/style.CbyL3DX2.css" as="style">
    <link rel="preload stylesheet" href="/vitepress-llm-recommends/vp-icons.css" as="style">
    
    <script type="module" src="/vitepress-llm-recommends/assets/app.CxDjSkIe.js"></script>
    <link rel="preload" href="/vitepress-llm-recommends/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/vitepress-llm-recommends/assets/chunks/theme.WU6Zdw17.js">
    <link rel="modulepreload" href="/vitepress-llm-recommends/assets/chunks/framework.t7omRjYa.js">
    <link rel="modulepreload" href="/vitepress-llm-recommends/assets/recommendations_stem_index.md.BYY5hXAd.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-1df9f90f><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0b0ada53></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0b0ada53>Skip to content</a><!--]--><!----><header class="VPNav" data-v-1df9f90f data-v-9f75dce3><div class="VPNavBar" data-v-9f75dce3 data-v-2a96a3d0><div class="wrapper" data-v-2a96a3d0><div class="container" data-v-2a96a3d0><div class="title" data-v-2a96a3d0><div class="VPNavBarTitle has-sidebar" data-v-2a96a3d0 data-v-1e38c6bc><a class="title" href="/vitepress-llm-recommends/" data-v-1e38c6bc><!--[--><!--]--><!----><span data-v-1e38c6bc>AI Model Guide</span><!--[--><!--]--></a></div></div><div class="content" data-v-2a96a3d0><div class="content-body" data-v-2a96a3d0><!--[--><!--]--><div class="VPNavBarSearch search" data-v-2a96a3d0><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-2a96a3d0 data-v-39714824><span id="main-nav-aria-label" class="visually-hidden" data-v-39714824> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/evaluation/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Evaluation</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/inference/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Inference</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/model-types/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Model Types</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/vitepress-llm-recommends/recommendations/" tabindex="0" data-v-39714824 data-v-e56f3d57><!--[--><span data-v-e56f3d57>Recommendations</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-2a96a3d0 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-2a96a3d0 data-v-0394ad82 data-v-d07f11e6><!--[--><a class="VPSocialLink no-icon" href="https://github.com/MaxKruse/vitepress-llm-recommends/" aria-label="github" target="_blank" rel="me noopener" data-v-d07f11e6 data-v-591a6b30><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-2a96a3d0 data-v-bb2aa2f0 data-v-42cb505d><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-42cb505d><span class="vpi-more-horizontal icon" data-v-42cb505d></span></button><div class="menu" data-v-42cb505d><div class="VPMenu" data-v-42cb505d data-v-25a6cce8><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>Appearance</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-d07f11e6><!--[--><a class="VPSocialLink no-icon" href="https://github.com/MaxKruse/vitepress-llm-recommends/" aria-label="github" target="_blank" rel="me noopener" data-v-d07f11e6 data-v-591a6b30><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-2a96a3d0 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-2a96a3d0><div class="divider-line" data-v-2a96a3d0></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-1df9f90f data-v-8acdfeb5><div class="container" data-v-8acdfeb5><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-8acdfeb5><span class="vpi-align-left menu-icon" data-v-8acdfeb5></span><span class="menu-text" data-v-8acdfeb5>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-8acdfeb5 data-v-0bf0e06f><button data-v-0bf0e06f>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-1df9f90f data-v-e7c6e512><div class="curtain" data-v-e7c6e512></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-e7c6e512><span class="visually-hidden" id="sidebar-aria-label" data-v-e7c6e512> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Introduction</h2><!----></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Home</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Evaluation</h2><!----></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/evaluation/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Inference</h2><!----></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/inference/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0 collapsible" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Model Types</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-d81de50c><span class="vpi-chevron-right caret-icon" data-v-d81de50c></span></div></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/model-types/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/model-types/dense/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Dense Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/model-types/mixture-of-experts/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Mixture of Experts (MoE)</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0 collapsible has-active" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Recommendations</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-d81de50c><span class="vpi-chevron-right caret-icon" data-v-d81de50c></span></div></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/coding/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Coding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/instruct/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Instruct-Tuned</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/personal-assistant/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Personal Assistant</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/stem/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>STEM</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/vitepress-llm-recommends/recommendations/storywriting/" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Storywriting</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-1df9f90f data-v-aff0b8d7><div class="VPDoc has-sidebar has-aside" data-v-aff0b8d7 data-v-7011f0d8><!--[--><!--]--><div class="container" data-v-7011f0d8><div class="aside" data-v-7011f0d8><div class="aside-curtain" data-v-7011f0d8></div><div class="aside-container" data-v-7011f0d8><div class="aside-content" data-v-7011f0d8><div class="VPDocAside" data-v-7011f0d8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-60d5052e><div class="content" data-v-60d5052e><div class="outline-marker" data-v-60d5052e></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-60d5052e>On this page</div><ul class="VPDocOutlineItem root" data-v-60d5052e data-v-2d0bdf9b><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-7011f0d8><div class="content-container" data-v-7011f0d8><!--[--><!--]--><main class="main" data-v-7011f0d8><div style="position:relative;" class="vp-doc _vitepress-llm-recommends_recommendations_stem_" data-v-7011f0d8><div data-v-2a6cc8a1><h1 id="stem-science-technology-engineering-mathematics" tabindex="-1" data-v-2a6cc8a1>STEM (Science, Technology, Engineering, Mathematics) <a class="header-anchor" href="#stem-science-technology-engineering-mathematics" aria-label="Permalink to “STEM (Science, Technology, Engineering, Mathematics)”" data-v-2a6cc8a1>​</a></h1><p data-v-2a6cc8a1><strong data-v-2a6cc8a1>Thinking-tuned models</strong> optimized for technical reasoning, mathematical precision, scientific problem-solving, and code-heavy workflows. These models excel at tasks like deriving equations, debugging complex systems, simulating experiments, and explaining STEM concepts with rigor.</p><blockquote data-v-2a6cc8a1><p data-v-2a6cc8a1>💡 <strong data-v-2a6cc8a1>Note</strong>: All models listed below are <em data-v-2a6cc8a1>thinking-tuned variants</em> (e.g., <code data-v-2a6cc8a1>qwen3 4b thinking</code>), which are specifically fine-tuned for analytical depth—not general-purpose chat. They outperform standard instruct models on logic-heavy, multi-step STEM problems.</p></blockquote><p data-v-2a6cc8a1>Use the selector below to find the best <strong data-v-2a6cc8a1>thinking-tuned</strong> model for your hardware:</p><div class="recommended-4b model-selector" data-v-2a6cc8a1><div class="controls" data-v-2a6cc8a1><div class="control-group" data-v-2a6cc8a1><label for="ram-select" data-v-2a6cc8a1>RAM (GB)</label><select id="ram-select" data-v-2a6cc8a1><!--[--><option value="16" data-v-2a6cc8a1 selected>16</option><option value="32" data-v-2a6cc8a1>32</option><option value="64" data-v-2a6cc8a1>64</option><option value="128" data-v-2a6cc8a1>128</option><!--]--></select></div><div class="control-group" data-v-2a6cc8a1><label for="vram-select" data-v-2a6cc8a1>VRAM (GB)</label><select id="vram-select" data-v-2a6cc8a1><!--[--><option value="0" data-v-2a6cc8a1>0</option><option value="4" data-v-2a6cc8a1>4</option><option value="6" data-v-2a6cc8a1>6</option><option value="8" data-v-2a6cc8a1 selected>8</option><option value="12" data-v-2a6cc8a1>12</option><option value="16" data-v-2a6cc8a1>16</option><option value="24" data-v-2a6cc8a1>24</option><option value="32" data-v-2a6cc8a1>32</option><!--]--></select></div></div><div class="result" data-v-2a6cc8a1><strong data-v-2a6cc8a1>Recommended model:</strong><span class="recommended-4b model-name" style="background-color:var(--vp-c-orange-soft);color:var(--vp-c-orange-2);" data-v-2a6cc8a1>Qwen3-4B-Thinking Q8</span></div></div><blockquote data-v-2a6cc8a1><p data-v-2a6cc8a1><strong data-v-2a6cc8a1>“Not recommended” means unreliable STEM output</strong> If the selector returns “Not recommended,” your system likely lacks the resources to run even the smallest thinking model effectively. In such cases, output quality degrades severely—often worse than manually reasoning through the problem for 5+ minutes.</p></blockquote><hr data-v-2a6cc8a1><h2 id="how-to-use-thinking-tuned-models-for-stem-work" tabindex="-1" data-v-2a6cc8a1>How to Use Thinking-Tuned Models for STEM Work <a class="header-anchor" href="#how-to-use-thinking-tuned-models-for-stem-work" aria-label="Permalink to “How to Use Thinking-Tuned Models for STEM Work”" data-v-2a6cc8a1>​</a></h2><p data-v-2a6cc8a1>These models are designed for <strong data-v-2a6cc8a1>deep technical reasoning</strong>, not casual conversation. Follow these guidelines to maximize accuracy and performance in scientific, engineering, or mathematical contexts.</p><h3 id="_1-use-only-thinking-tuned-variants" tabindex="-1" data-v-2a6cc8a1>1. <strong data-v-2a6cc8a1>Use Only Thinking-Tuned Variants</strong> <a class="header-anchor" href="#_1-use-only-thinking-tuned-variants" aria-label="Permalink to “1. Use Only Thinking-Tuned Variants”" data-v-2a6cc8a1>​</a></h3><ul data-v-2a6cc8a1><li data-v-2a6cc8a1>Only models labeled <strong data-v-2a6cc8a1><code data-v-2a6cc8a1>thinking</code></strong> (e.g., <code data-v-2a6cc8a1>qwen3 4b thinking</code>, <code data-v-2a6cc8a1>qwen3 30b thinking</code>) are fine-tuned for analytical tasks like: <ul data-v-2a6cc8a1><li data-v-2a6cc8a1>Solving differential equations</li><li data-v-2a6cc8a1>Deriving physics formulas</li><li data-v-2a6cc8a1>Debugging numerical simulations</li><li data-v-2a6cc8a1>Explaining quantum mechanics or circuit design</li></ul></li><li data-v-2a6cc8a1>Standard <code data-v-2a6cc8a1>instruct</code> or base models often <strong data-v-2a6cc8a1>fail on multi-step logic</strong> or produce plausible but incorrect STEM conclusions.</li></ul><h3 id="_2-understand-quantization-trade-offs" tabindex="-1" data-v-2a6cc8a1>2. <strong data-v-2a6cc8a1>Understand Quantization Trade-offs</strong> <a class="header-anchor" href="#_2-understand-quantization-trade-offs" aria-label="Permalink to “2. Understand Quantization Trade-offs”" data-v-2a6cc8a1>​</a></h3><table tabindex="0" data-v-2a6cc8a1><thead data-v-2a6cc8a1><tr data-v-2a6cc8a1><th data-v-2a6cc8a1>Quant</th><th data-v-2a6cc8a1>Use Case</th><th data-v-2a6cc8a1>STEM Impact</th></tr></thead><tbody data-v-2a6cc8a1><tr data-v-2a6cc8a1><td data-v-2a6cc8a1><code data-v-2a6cc8a1>bf16</code> / <code data-v-2a6cc8a1>f16</code></td><td data-v-2a6cc8a1>High-precision math, symbolic reasoning</td><td data-v-2a6cc8a1>Best for accuracy in calculus, linear algebra, or physics derivations</td></tr><tr data-v-2a6cc8a1><td data-v-2a6cc8a1><code data-v-2a6cc8a1>q8</code></td><td data-v-2a6cc8a1>Balanced performance</td><td data-v-2a6cc8a1>Suitable for most coding + math tasks (e.g., Python + NumPy workflows)</td></tr><tr data-v-2a6cc8a1><td data-v-2a6cc8a1><code data-v-2a6cc8a1>q6</code> / <code data-v-2a6cc8a1>q4</code></td><td data-v-2a6cc8a1>Low-resource systems</td><td data-v-2a6cc8a1>May skip steps in proofs or mis-evaluate edge cases—use only when necessary</td></tr></tbody></table><h3 id="_3-full-gpu-offload-is-critical" tabindex="-1" data-v-2a6cc8a1>3. <strong data-v-2a6cc8a1>Full GPU Offload Is Critical</strong> <a class="header-anchor" href="#_3-full-gpu-offload-is-critical" aria-label="Permalink to “3. Full GPU Offload Is Critical”" data-v-2a6cc8a1>​</a></h3><ul data-v-2a6cc8a1><li data-v-2a6cc8a1><strong data-v-2a6cc8a1>Context lives in VRAM</strong>—always aim for <strong data-v-2a6cc8a1>full GPU offload</strong> (e.g., 48/48 layers in LM Studio).</li><li data-v-2a6cc8a1>If LM Studio suggests default offload settings for a model, <strong data-v-2a6cc8a1>keep them</strong>—they&#39;re tuned for stability.</li></ul><h3 id="_4-ram-vram-combo-rule-for-cpu-offload" tabindex="-1" data-v-2a6cc8a1>4. <strong data-v-2a6cc8a1>RAM+VRAM Combo Rule (For CPU Offload)</strong> <a class="header-anchor" href="#_4-ram-vram-combo-rule-for-cpu-offload" aria-label="Permalink to “4. RAM+VRAM Combo Rule (For CPU Offload)”" data-v-2a6cc8a1>​</a></h3><p data-v-2a6cc8a1>If using partial CPU offload:</p><div class="language-" data-v-2a6cc8a1><button title="Copy Code" class="copy" data-v-2a6cc8a1></button><span class="lang" data-v-2a6cc8a1></span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr" data-v-2a6cc8a1><code data-v-2a6cc8a1><span class="line" data-v-2a6cc8a1><span data-v-2a6cc8a1>Total Free RAM + VRAM ≥ Model Size + 4 GB (context + overhead)</span></span></code></pre></div><ul data-v-2a6cc8a1><li data-v-2a6cc8a1>Example: <code data-v-2a6cc8a1>qwen3-30b-thinking-q8</code> ≈ 36 GB → requires <strong data-v-2a6cc8a1>≥40 GB combined free memory</strong>.</li><li data-v-2a6cc8a1>This setup works but is <strong data-v-2a6cc8a1>not ideal for real-time STEM exploration</strong>—expect latency.</li></ul><h3 id="_5-prompt-with-precision" tabindex="-1" data-v-2a6cc8a1>5. <strong data-v-2a6cc8a1>Prompt with Precision</strong> <a class="header-anchor" href="#_5-prompt-with-precision" aria-label="Permalink to “5. Prompt with Precision”" data-v-2a6cc8a1>​</a></h3><p data-v-2a6cc8a1>STEM models thrive on <strong data-v-2a6cc8a1>structured, explicit prompts</strong>:</p><ul data-v-2a6cc8a1><li data-v-2a6cc8a1>❌ <em data-v-2a6cc8a1>“How do I solve this?”</em></li><li data-v-2a6cc8a1>✅ <em data-v-2a6cc8a1>“Given a 2D heat equation ∂u/∂t = α∇²u on [0,1]×[0,1] with Dirichlet BCs, derive the finite difference scheme using central differences and Δx=Δy=0.1.”</em></li><li data-v-2a6cc8a1>Include: <ul data-v-2a6cc8a1><li data-v-2a6cc8a1>Known variables &amp; constraints</li><li data-v-2a6cc8a1>Desired output format (e.g., “show all steps,” “return Python code”)</li><li data-v-2a6cc8a1>Relevant domain (e.g., “in classical electromagnetism…”)</li></ul></li></ul><h3 id="_6-avoid-none-configurations" tabindex="-1" data-v-2a6cc8a1>6. <strong data-v-2a6cc8a1>Avoid “None” Configurations</strong> <a class="header-anchor" href="#_6-avoid-none-configurations" aria-label="Permalink to “6. Avoid “None” Configurations”" data-v-2a6cc8a1>​</a></h3><ul data-v-2a6cc8a1><li data-v-2a6cc8a1>If your hardware yields <strong data-v-2a6cc8a1>“none”</strong>, do <strong data-v-2a6cc8a1>not</strong> force a model load via heavy CPU offload.</li><li data-v-2a6cc8a1>You&#39;ll get <strong data-v-2a6cc8a1>hallucinated derivations</strong>, incorrect unit conversions, or broken logic—worse than no model at all.</li><li data-v-2a6cc8a1>Alternatives: <ul data-v-2a6cc8a1><li data-v-2a6cc8a1>Use cloud inference (e.g., Together.ai with <code data-v-2a6cc8a1>qwen3-30b-thinking</code>)</li><li data-v-2a6cc8a1>Upgrade to ≥8 GB VRAM for basic STEM tasks</li></ul></li></ul><h3 id="_7-monitor-real-time-usage" tabindex="-1" data-v-2a6cc8a1>7. <strong data-v-2a6cc8a1>Monitor Real-Time Usage</strong> <a class="header-anchor" href="#_7-monitor-real-time-usage" aria-label="Permalink to “7. Monitor Real-Time Usage”" data-v-2a6cc8a1>​</a></h3><ul data-v-2a6cc8a1><li data-v-2a6cc8a1><strong data-v-2a6cc8a1>Windows</strong>: Task Manager → Performance → GPU &amp; Memory</li><li data-v-2a6cc8a1><strong data-v-2a6cc8a1>Linux</strong>: <code data-v-2a6cc8a1>nvidia-smi</code> (NVIDIA) or <code data-v-2a6cc8a1>radeontop</code> (AMD)</li><li data-v-2a6cc8a1>If VRAM &gt;90% usage, reduce context length or switch to a lower quant (e.g., <code data-v-2a6cc8a1>bf16</code> → <code data-v-2a6cc8a1>q8</code>).</li></ul><hr data-v-2a6cc8a1><p data-v-2a6cc8a1>By aligning your hardware capabilities, quantization choice, and prompt engineering with these principles, you&#39;ll unlock <strong data-v-2a6cc8a1>reliable, step-by-step technical reasoning</strong>—whether you&#39;re proving theorems, simulating systems, or designing experiments.</p></div></div></main><footer class="VPDocFooter" data-v-7011f0d8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/vitepress-llm-recommends/recommendations/personal-assistant/" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Previous page</span><span class="title" data-v-e257564d>Personal Assistant</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/vitepress-llm-recommends/recommendations/storywriting/" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>Storywriting</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-1df9f90f data-v-c3855bb3><div class="container" data-v-c3855bb3><p class="message" data-v-c3855bb3>Released under the MIT License.</p><p class="copyright" data-v-c3855bb3>Copyright © 2025 Maximilian Kruse</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"evaluation_index.md\":\"CQaje612\",\"index.md\":\"D0wSj2Q9\",\"inference_index.md\":\"Dgy3BO6N\",\"model-types_dense_index.md\":\"CEoH8TAt\",\"model-types_index.md\":\"DNOmDuiS\",\"model-types_mixture-of-experts_index.md\":\"jQ3fok6t\",\"recommendations_coding_index.md\":\"CO_7g-yb\",\"recommendations_index.md\":\"CBvKaARS\",\"recommendations_instruct_index.md\":\"BPMjm1CH\",\"recommendations_personal-assistant_index.md\":\"x_dFXD1i\",\"recommendations_stem_index.md\":\"BYY5hXAd\",\"recommendations_storywriting_index.md\":\"BAZ6SNKA\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"AI Model Guide\",\"description\":\"A practical guide to understanding and using modern AI models.\",\"base\":\"/vitepress-llm-recommends/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Evaluation\",\"link\":\"/evaluation/\"},{\"text\":\"Inference\",\"link\":\"/inference/\"},{\"text\":\"Model Types\",\"link\":\"/model-types/\"},{\"text\":\"Recommendations\",\"link\":\"/recommendations/\"}],\"sidebar\":[{\"text\":\"Introduction\",\"items\":[{\"text\":\"Home\",\"link\":\"/\"}]},{\"text\":\"Evaluation\",\"items\":[{\"text\":\"Overview\",\"link\":\"/evaluation/\"}]},{\"text\":\"Inference\",\"items\":[{\"text\":\"Overview\",\"link\":\"/inference/\"}]},{\"text\":\"Model Types\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/model-types/\"},{\"text\":\"Dense Models\",\"link\":\"/model-types/dense/\"},{\"text\":\"Mixture of Experts (MoE)\",\"link\":\"/model-types/mixture-of-experts/\"}]},{\"text\":\"Recommendations\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/recommendations/\"},{\"text\":\"Coding\",\"link\":\"/recommendations/coding/\"},{\"text\":\"Instruct-Tuned\",\"link\":\"/recommendations/instruct/\"},{\"text\":\"Personal Assistant\",\"link\":\"/recommendations/personal-assistant/\"},{\"text\":\"STEM\",\"link\":\"/recommendations/stem/\"},{\"text\":\"Storywriting\",\"link\":\"/recommendations/storywriting/\"}]}],\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/MaxKruse/vitepress-llm-recommends/\"}],\"footer\":{\"message\":\"Released under the MIT License.\",\"copyright\":\"Copyright © 2025 Maximilian Kruse\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false,\"additionalConfig\":{}}");</script>
    
  </body>
</html>