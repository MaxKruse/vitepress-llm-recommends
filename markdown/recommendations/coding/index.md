---
title: Coding
---

# Coding Recommendations  
**Prioritizing Very High Precision in Code Generation, Completion, and Debugging**

When working with AI-assisted coding, **precision is non-negotiable**. Even minor hallucinations, syntactic errors, or incorrect logic can introduce bugs, security vulnerabilities, or maintenance debt. These recommendations are tailored for developers who require **extremely high-fidelity outputs**â€”not just plausible-looking code, but **correct, production-ready, and logically sound** implementations.

Use the selector below to identify the best model **that balances your hardware constraints with the highest achievable precision**:

<script setup>
import { ref, computed } from 'vue'

const ram = ref(16)
const vram = ref(8)

// Define the available options
const ramOptions = [16, 32, 64, 128]
const vramOptions = [0, 4, 6, 8, 12, 16, 24, 32]

// Define your recommendation rules here - much easier to maintain!
const recommendationRules = [
  // High VRAM, high RAM - bf16 precision
  { ramMin: 64, vramMin: 16, model: "Qwen3 Coder 30B A3B Instruct bf16", color: "var(--vp-c-green-2)", bg: "var(--vp-c-green-soft)" },
  // High VRAM, medium RAM - bf16 precision
  { ramMin: 32, vramMin: 16, model: "Qwen3 Coder 30B A3B Instruct Q8", color: "var(--vp-c-green-2)", bg: "var(--vp-c-green-soft)" },
  // Lower VRAM, higher RAM - Q6 precision
  { ramMin: 32, vramMin: 6, model: "Qwen3 Coder 30B A3B Instruct Q6", color: "var(--vp-c-yellow-2)", bg: "var(--vp-c-yellow-soft)" },
  // Low VRAM - 4B models
  { ramMin: 16, vramMin: 4, model: "Qwen3 4B Instruct 2507 BF16", color: "var(--vp-c-purple-2)", bg: "var(--vp-c-purple-soft)" },
]

const recommendedModel = computed(() => {
  // Find the first rule that matches the current RAM and VRAM
  const matchingRule = recommendationRules.find(rule => ram.value >= rule.ramMin && vram.value >= rule.vramMin)
  
  if (matchingRule) {
    return {
      model: matchingRule.model,
      color: matchingRule.color,
      bg: matchingRule.bg
    }
  }
  
  return {
    model: 'Not recommended',
    color: 'var(--vp-c-text-3)',
    bg: 'transparent'
  }
})

const isRecommended = computed(() => {
  return recommendedModel.value.model !== 'Not recommended'
})

/* Normalized detection + canonical classes */
const normalizedModel = computed(() => recommendedModel.value.model.toLowerCase())

const isBF16orGPTOSS = computed(() =>
  normalizedModel.value.includes('bf16') || normalizedModel.value.includes('gpt oss')
)

const isQ6orQ8 = computed(() =>
  normalizedModel.value.includes('q6') || normalizedModel.value.includes('q8')
)

const isQ4 = computed(() => normalizedModel.value.includes('q4'))

const is4b = computed(() => normalizedModel.value.includes('4b'))

const selectorClass = computed(() => {
  if (!isRecommended.value) return { 'not-recommended': true }
  if (is4b.value) return { 'recommended-4b': true }
  if (isBF16orGPTOSS.value) return { 'recommended-success': true }
  if (isQ6orQ8.value) return { 'recommended-caution': true }
  if (isQ4.value) return { 'recommended-warning': true }
  return {}
})

const modelNameClasses = computed(() => {
  if (!isRecommended.value) return { 'not-recommended': true }
  if (is4b.value) return { 'recommended-4b': true }
  if (isBF16orGPTOSS.value) return { 'recommended-success': true }
  if (isQ6orQ8.value) return { 'recommended-caution': true }
  if (isQ4.value) return { 'recommended-warning': true }
  return {}
})
</script>

<style scoped>
.model-selector {
  margin: 2rem 0;
  padding: 1.5rem;
  border-radius: 16px;
  background-color: var(--vp-code-block-bg);
  border: 2px solid var(--vp-c-border); /* Default border */
  font-size: 0.95rem;
  transition: border-color 0.3s ease;
  position: relative;
  overflow: hidden; /* Ensures background colors stay within bounds */
}

.model-selector::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  height: 4px;
  background: linear-gradient(90deg, var(--vp-c-brand), var(--vp-c-green));
  /* Default gradient, will be overridden by JavaScript or specific class if needed */
}

/* Example: Specific border color based on recommendation */
.model-selector.recommended-success {
  border-color: var(--vp-c-green-2);
}
.model-selector.recommended-caution {
  border-color: var(--vp-c-yellow-2);
}
.model-selector.recommended-warning {
  border-color: var(--vp-c-orange-2);
}
.model-selector.recommended-4b {
  border-color: var(--vp-c-purple-2);
}

.model-selector h3 {
  margin-top: 0;
  margin-bottom: 1.25rem;
  font-weight: 600;
  color: var(--vp-c-text-1);
}

.controls {
  display: flex;
  flex-wrap: wrap;
  gap: 1.25rem;
  margin-bottom: 1.5rem;
}

.control-group {
  display: flex;
  flex-direction: column;
  min-width: 150px;
}

.control-group label {
  font-weight: 500;
  margin-bottom: 0.5rem;
  color: var(--vp-c-text-1);
  font-size: 0.9rem;
}

.control-group select {
  padding: 0.6rem 0.8rem;
  border: 1px solid var(--vp-c-border);
  border-radius: 8px;
  background: var(--vp-c-bg);
  color: var(--vp-c-text-1);
  font-size: 0.95rem;
  transition: all 0.2s ease;
  box-shadow: 0 1px 2px rgba(0, 0, 0, 0.05);
}

.control-group select:hover {
  border-color: var(--vp-c-brand-lighter);
}

.control-group select:focus {
  outline: none;
  border-color: var(--vp-c-brand);
  box-shadow: 0 0 0 3px rgba(66, 133, 244, 0.25);
}

.result {
  padding-top: 1rem;
  border-top: 1px solid var(--vp-c-divider);
}

.result strong {
  display: block;
  margin-bottom: 0.5rem;
  font-weight: 500;
  color: var(--vp-c-text-1);
}

.result .model-name {
  display: inline-block;
  padding: 0.5rem 0.75rem;
  border-radius: 8px;
  font-family: var(--vp-font-family-mono);
  font-size: 0.95em;
  font-weight: 500;
  transition: all 0.3s ease;
  border: 1px solid transparent; /* Default border */
}

.result .model-name.not-recommended {
  color: var(--vp-c-text-3);
  background: var(--vp-c-bg-soft);
  border-color: var(--vp-c-text-3);
  font-style: italic;
}

/* Dynamically applied styles based on recommendation level */
.result .model-name.recommended-success {
  background-color: var(--vp-c-green-soft);
  color: var(--vp-c-green-2);
  border-color: var(--vp-c-green-2);
}
 
.result .model-name.recommended-caution {
  background-color: var(--vp-c-yellow-soft);
  color: var(--vp-c-yellow-2);
  border-color: var(--vp-c-yellow-2);
}
 
.result .model-name.recommended-warning {
  background-color: var(--vp-c-orange-soft);
  color: var(--vp-c-orange-2);
  border-color: var(--vp-c-orange-2);
}
 
.result .model-name.recommended-4b {
  background-color: var(--vp-c-purple-soft);
  color: var(--vp-c-purple-2);
  border-color: var(--vp-c-purple-2);
}
 
</style>

<div class="model-selector" :class="selectorClass">
  <div class="controls">
    <div class="control-group">
      <label for="ram-select">RAM (GB)</label>
      <select id="ram-select" v-model.number="ram">
        <option v-for="r in ramOptions" :key="r" :value="r">{{ r }}</option>
      </select>
    </div>
    <div class="control-group">
      <label for="vram-select">VRAM (GB)</label>
      <select id="vram-select" v-model.number="vram">
        <option v-for="v in vramOptions" :key="v" :value="v">{{ v }}</option>
      </select>
    </div>
  </div>

  <div class="result">
    <strong>Recommended model:</strong>
    <span
      class="model-name"
      :class="modelNameClasses"
      :style="{ backgroundColor: recommendedModel.bg, color: recommendedModel.color }"
    >
      {{ recommendedModel.model }}
    </span>
  </div>
</div>

## Why Precision Matters in Coding

Unlike creative or conversational tasks, **code must be functionally correct**. A model that â€œsounds rightâ€ but produces broken logic, incorrect APIs, or unsafe patterns is worse than no model at all. Therefore, **favor models and configurations that maximize precisionâ€”even at the cost of speed or resource usage**.

### 1. **Use Full GPU Offload (When Possible)**
- In **LM Studio**, always enable **full GPU offload** (e.g., `48/48` layers for Qwen3 models).

### 2. **Prefer Instruct-Tuned, Code-Specialized Models**
- Only use **code-instruct variants** like `qwen3-coder-30b-instruct`. These are fine-tuned on millions of correct code examples and aligned for **semantic and syntactic accuracy**.
- Avoid base models or â€œthinkingâ€ variantsâ€”they lack the precision tuning needed for reliable code output.

### 3. **Context Window & Memory Stability**
- All recommendations assume a **stable ~16K context window**.

### 4. **Quantization: Precision vs. Practicality**
| Quant | Speed | **Precision** | VRAM Use |
|------|-------|--------------|--------|
| `bf16` / `f16` | â˜…â˜†â˜†â˜†â˜† | â˜…â˜…â˜…â˜…â˜… (**Highest**) | Highest |
| `q8` | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜…â˜…â˜† (**High**) | Medium-High |
| `q6` | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜†â˜† (**Moderate**) | Medium |
| `q4` | â˜…â˜…â˜…â˜…â˜… | â˜…â˜†â˜†â˜†â˜† (**Low - Not Recommended for Precision Work**) | Lowest |

> ðŸ’¡ **For high-stakes coding (e.g., production systems, security-sensitive logic, or complex algorithms), always prefer `bf16`, `f16`, or at minimum `q8`.** Avoid `q4` unless absolutely necessaryâ€”it sacrifices too much precision.

### 5. **Prompt Engineering for Correctness**
- **Be explicit and constrained**:  
  âŒ _â€œWrite a login function.â€_  
  âœ… _â€œWrite a secure Python FastAPI login endpoint using OAuth2 password flow, with bcrypt hashing, rate limiting, and proper error responses.â€_
- **Request verification steps**: Ask the model to â€œexplain why this implementation is safeâ€ or â€œlist potential edge cases.â€
- **Include error context**: Paste stack traces or test failuresâ€”this helps the model reason precisely about the failure mode.

### 6. **Avoid â€œNoneâ€ or Underpowered Setups**
- If the matrix returns **â€œnoneâ€**, **do not force execution** via heavy RAM offloading.
- Under-resourced inference **increases hallucination rates** and reduces logical consistencyâ€”**unacceptable for precision-critical workflows**.
- Consider cloud inference (e.g., with `bf16` models) if local hardware is insufficient.

### 7. **Validate and Monitor**
- **Never trust output blindly**. Always:
  - Run static analysis (e.g., `mypy`, `eslint`, `bandit`)
  - Execute unit tests
  - Review for logic correctness
- Monitor VRAM usage: sustained >95% utilization can cause **numerical errors** that silently degrade output quality.

---

By aligning your tooling with the **highest-precision models your hardware can support**, you ensure that AI assistance enhancesâ€”rather than underminesâ€”code quality, security, and maintainability. **When correctness is paramount, precision isn't optionalâ€”it's essential.**