import{_ as a,c as t,o as i,af as o}from"./chunks/framework.CuQK53I8.js";const m=JSON.parse('{"title":"Recommendations","description":"","frontmatter":{"title":"Recommendations"},"headers":[],"relativePath":"recommendations/index.md","filePath":"recommendations/index.md"}'),n={name:"recommendations/index.md"};function s(r,e,l,h,c,u){return i(),t("div",null,[...e[0]||(e[0]=[o('<h1 id="recommendations" tabindex="-1">Recommendations <a class="header-anchor" href="#recommendations" aria-label="Permalink to “Recommendations”">​</a></h1><p>Choose the right model and hardware setup based on your specific use case. Below are tailored guides for common scenarios:</p><ul><li><p><a href="./coding/"><strong>Coding Assistants</strong></a><br> Models and hardware for code generation, autocomplete, and debugging.</p></li><li><p><a href="./instruct/"><strong>Instruction-Following Tasks</strong></a><br> Best choices for chatbots, customer support, and general-purpose assistants.</p></li><li><p><a href="./personal-assistant/"><strong>Personal AI Assistants</strong></a><br> Optimized setups for private, responsive, and context-aware daily use.</p></li><li><p><a href="./stem/"><strong>STEM &amp; Technical Reasoning</strong></a><br> Models with strong math, logic, and scientific reasoning capabilities.</p></li><li><p><a href="./storywriting/"><strong>Creative Storywriting</strong></a><br> Architectures and configurations for long-form, coherent, and imaginative text.</p></li></ul><p>Each guide includes model suggestions, quantization tips, and minimum/recommended hardware specs.</p><h2 id="parameters-quantization-and-hallucinations" tabindex="-1">Parameters, Quantization, and Hallucinations <a class="header-anchor" href="#parameters-quantization-and-hallucinations" aria-label="Permalink to “Parameters, Quantization, and Hallucinations”">​</a></h2><p>This section explores the core concepts you&#39;ll encounter when working with local LLMs: parameters, quantization, and hallucinations.</p><h3 id="what-are-parameters" tabindex="-1">What are Parameters? <a class="header-anchor" href="#what-are-parameters" aria-label="Permalink to “What are Parameters?”">​</a></h3><p>In an LLM, <strong>parameters</strong> are the internal variables the model learns during training. Think of them as the neurons and the connections between them. The number of parameters determines the model&#39;s capacity to store and process information.</p><ul><li><strong>Model Size</strong>: Modern models typically become useful out-of-the-box starting around 1-4 billion (B) parameters.</li><li><strong>Data Precision</strong>: Most models are initially trained in <strong>FP16</strong> (16-bit floating point), meaning each parameter can hold 16 bits of information.</li></ul><p>The more parameters a model has, the more potential space there is for information to be learned without &quot;overwriting&quot; previously learned knowledge.</p><h4 id="the-role-of-training" tabindex="-1">The Role of Training <a class="header-anchor" href="#the-role-of-training" aria-label="Permalink to “The Role of Training”">​</a></h4><p>Sadly, as of late 2025, most consumer-level LLMs are heavily undertrained. This becomes evident when we apply quantization (explained below).</p><p>To put it simply: if there are 16 bits of space available in a parameter, but on average, only 4 of those bits are effectively used during training, the other 12 bits contribute very little to the final output quality. This is why you&#39;ll often see recommendations for extreme quantization methods like <strong>Q4</strong> (an average of 4 bits per parameter) or even lower.</p><p>To illustrate the relationship between model size, training, and quantization:</p><p>Imagine we take a 4B model and a 70B model from the same family.</p><ol><li>We train both on the exact same data for the same number of iterations.</li><li>The smaller 4B model might become &quot;full,&quot; saturating most of the 16 bits in its 4 billion parameters.</li><li>The larger 70B model, with its vast capacity, might only effectively use, let&#39;s say, 8 bits of information per parameter on average.</li></ol><p>Now, if we quantize both models to <strong>Q4</strong>:</p><ul><li>The 4B model loses a significant amount of its learned data (going from ~16 bits to 4 bits).</li><li>The 70B model is less affected because it was only using ~8 bits of information anyway. Its perceived quality drop is much smaller.</li></ul><p>This is why quantizing a massive, undertrained 70B model to Q4 is often less of an issue than quantizing an 8B model of the same family, or comparing it to better-trained models like the <strong>Qwen3 Family (which is NOT undertrained and utilizes all 16 bits very effectively)</strong>.</p><h3 id="what-is-quantization" tabindex="-1">What is Quantization? <a class="header-anchor" href="#what-is-quantization" aria-label="Permalink to “What is Quantization?”">​</a></h3><p>Quantization is the process of reducing the precision of a model&#39;s parameters to save memory and improve performance.</p><p>Imagine a single 16-bit parameter (<code>0011010101110101</code>) represents the following detailed information:</p><blockquote><p>Leaves appear green because of chlorophyll, a pigment found inside plant cells (specifically in chloroplasts). Chlorophyll plays a critical role in photosynthesis, the process plants use to convert light energy into chemical energy.</p><p>Sunlight contains all wavelengths (colors) of visible light. Chlorophyll absorbs light most efficiently in the blue (~430-450 nm) and red (~640-680 nm) regions of the spectrum, which are used to drive photosynthesis.</p><p>However, it reflects and transmits green light (~500-550 nm) rather than absorbing it. Because the green wavelengths are not absorbed, they bounce off the leaf and enter our eyes — that&#39;s why we perceive leaves as green.</p></blockquote><p>If we quantize this 16-bit value down to just 4 bits (<code>0011</code>), we are essentially &quot;cutting off&quot; the fine-grained details. The model might now only retain enough information to generate a simpler explanation:</p><blockquote><p>Leaves are green because they have a special color helper inside called chlorophyll.</p><p>The leaf uses sunlight to make its food, kind of like how you eat to get energy. Chlorophyll drinks up red and blue sunlight but doesn&#39;t like green light — it bounces the green light away.</p><p>That&#39;s what your eyes see, so the leaf looks green!</p></blockquote><p>By removing detail, you risk losing accuracy. While the quantized model still seems to understand the core concept, it has lost nuance and is more likely to make mistakes or hallucinate.</p><h3 id="what-are-hallucinations" tabindex="-1">What are Hallucinations? <a class="header-anchor" href="#what-are-hallucinations" aria-label="Permalink to “What are Hallucinations?”">​</a></h3><p>LLMs famously &quot;hallucinate&quot;—they generate confident-sounding but incorrect or nonsensical information. While the exact cause is complex, you can think of it like this:</p><p>Imagine you know many different topics, but only at a very surface level. If someone asks you a question that <em>seems</em> like it could be answered by combining facts from different topics, you might construct an answer that sounds plausible but is ultimately wrong.</p><p>Consider an LLM that has learned the following isolated facts:</p><ol><li>Streets are clean because the city pays for cleaning them.</li><li>Your house is clean because your parents clean it from time to time.</li><li>The local McDonald&#39;s is never clean because the workers are too busy.</li></ol><p>If you ask the LLM, &quot;Why is my house not clean?&quot; it might correctly infer, &quot;Because your parents are busy.&quot;</p><p>However, it could also incorrectly combine unrelated facts and produce a hallucination:</p><blockquote><p>&quot;Your house is not clean because the city is not paying your parents.&quot;</p></blockquote>',34)])])}const p=a(n,[["render",s]]);export{m as __pageData,p as default};
