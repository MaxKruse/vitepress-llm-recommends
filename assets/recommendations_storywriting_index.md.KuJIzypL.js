import{_,x as h,h as r,c as v,o as c,j as e,af as k,a as l,ag as y,ah as S,G as M,H as w,t as m,O as C,n as B}from"./chunks/framework.t7omRjYa.js";const Q={class:"controls"},q={class:"control-group"},N=["value"],U={class:"control-group"},V=["value"],A={class:"result"},F=JSON.parse('{"title":"Storywriting","description":"","frontmatter":{"title":"Storywriting"},"headers":[],"relativePath":"recommendations/storywriting/index.md","filePath":"recommendations/storywriting/index.md"}'),I={name:"recommendations/storywriting/index.md"},z=Object.assign(I,{setup(R){const s=h(16),d=h(8),G=[16,32,64,128],P=[0,4,6,8,12,16,24,32],T=[{ramMin:128,vramMin:32,model:"GPT OSS 120B or Gemma 3 27B Q8",color:"var(--vp-c-green-2)",bg:"var(--vp-c-green-soft)"},{ramMin:128,vramMin:24,model:"GPT OSS 120B or Gemma 3 27B Q6",color:"var(--vp-c-green-2)",bg:"var(--vp-c-green-soft)"},{ramMin:128,vramMin:16,model:"GPT OSS 120B or Gemma 3 12B Q8",color:"var(--vp-c-green-2)",bg:"var(--vp-c-green-soft)"},{ramMin:128,vramMin:12,model:"GPT OSS 120B or Gemma 3 12B Q6",color:"var(--vp-c-green-2)",bg:"var(--vp-c-green-soft)"},{ramMin:128,vramMin:8,model:"GPT OSS 120B",color:"var(--vp-c-green-2)",bg:"var(--vp-c-green-soft)"},{ramMin:128,vramMin:6,model:"GPT OSS 120B",color:"var(--vp-c-green-2)",bg:"var(--vp-c-green-soft)"},{ramMin:128,vramMin:4,model:"GPT OSS 120B",color:"var(--vp-c-green-2)",bg:"var(--vp-c-green-soft)"},{ramMin:128,vramMin:0,model:"GPT OSS 120B",color:"var(--vp-c-green-2)",bg:"var(--vp-c-green-soft)"},{ramMin:64,vramMin:32,model:"GPT OSS 20B or Gemma 3 27B Q8",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:64,vramMin:24,model:"GPT OSS 20B or Gemma 3 27B Q6",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:64,vramMin:16,model:"GPT OSS 20B or Gemma 3 12B Q8",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:64,vramMin:12,model:"GPT OSS 20B or Gemma 3 12B Q6",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:64,vramMin:8,model:"GPT OSS 20B",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:64,vramMin:6,model:"GPT OSS 20B",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:64,vramMin:4,model:"GPT OSS 20B",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:64,vramMin:0,model:"GPT OSS 20B",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:32,vramMin:32,model:"GPT OSS 20B or Gemma 3 27B Q8",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:32,vramMin:24,model:"GPT OSS 20B or Gemma 3 27B Q6",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:32,vramMin:16,model:"GPT OSS 20B or Gemma 3 12B Q8",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:32,vramMin:12,model:"GPT OSS 20B or Gemma 3 12B Q6",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:32,vramMin:8,model:"GPT OSS 20B or Gemma 3 12B Q4",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:32,vramMin:6,model:"GPT OSS 20B",color:"var(--vp-c-blue-2)",bg:"var(--vp-c-blue-soft)"},{ramMin:16,vramMin:32,model:"GPT OSS 20B or Gemma 3 27B Q8",color:"var(--vp-c-orange-2)",bg:"var(--vp-c-orange-soft)"},{ramMin:16,vramMin:24,model:"GPT OSS 20B or Gemma 3 27B Q6",color:"var(--vp-c-orange-2)",bg:"var(--vp-c-orange-soft)"},{ramMin:16,vramMin:16,model:"GPT OSS 20B or Gemma 3 12B Q8",color:"var(--vp-c-orange-2)",bg:"var(--vp-c-orange-soft)"},{ramMin:16,vramMin:12,model:"GPT OSS 20B or Gemma 3 12B Q6",color:"var(--vp-c-orange-2)",bg:"var(--vp-c-orange-soft)"},{ramMin:16,vramMin:8,model:"Gemma 3 12B Q4",color:"var(--vp-c-orange-2)",bg:"var(--vp-c-orange-soft)"}],n=r(()=>{const i=T.find(a=>s.value>=a.ramMin&&d.value>=a.vramMin);return i?{model:i.model,color:i.color,bg:i.bg}:{model:"Not recommended",color:"var(--vp-c-text-3)",bg:"transparent"}}),u=r(()=>n.value.model!=="Not recommended"),o=r(()=>n.value.model.toLowerCase()),g=r(()=>o.value.includes("bf16")||o.value.includes("gpt oss")),p=r(()=>o.value.includes("q6")||o.value.includes("q8")),f=r(()=>o.value.includes("q4")),b=r(()=>o.value.includes("4b")),x=r(()=>u.value?b.value?{"recommended-4b":!0}:g.value?{"recommended-success":!0}:p.value?{"recommended-caution":!0}:f.value?{"recommended-warning":!0}:{}:{"not-recommended":!0}),O=r(()=>u.value?b.value?{"recommended-4b":!0}:g.value?{"recommended-success":!0}:p.value?{"recommended-caution":!0}:f.value?{"recommended-warning":!0}:{}:{"not-recommended":!0});return(i,a)=>(c(),v("div",null,[a[5]||(a[5]=e("h1",{id:"storywriting-creative-writing",tabindex:"-1"},[l("Storywriting & Creative Writing "),e("a",{class:"header-anchor",href:"#storywriting-creative-writing","aria-label":"Permalink to “Storywriting & Creative Writing”"},"​")],-1)),a[6]||(a[6]=e("p",null,[e("strong",null,"Narrative-tuned models"),l(" optimized for immersive storytelling, rich character arcs, evocative prose, and genre-aware stylistic control. These models excel at crafting original fiction, expanding existing worlds, generating dialogue with emotional nuance, and maintaining long-range plot coherence—even across tens of thousands of tokens.")],-1)),a[7]||(a[7]=e("p",null,[l("Use the selector below to find the best "),e("strong",null,"creative-writing-optimized"),l(" model for your hardware:")],-1)),e("div",{class:B(["model-selector",x.value])},[e("div",Q,[e("div",q,[a[2]||(a[2]=e("label",{for:"ram-select"},"RAM (GB)",-1)),y(e("select",{id:"ram-select","onUpdate:modelValue":a[0]||(a[0]=t=>s.value=t)},[(c(),v(M,null,w(G,t=>e("option",{key:t,value:t},m(t),9,N)),64))],512),[[S,s.value,void 0,{number:!0}]])]),e("div",U,[a[3]||(a[3]=e("label",{for:"vram-select"},"VRAM (GB)",-1)),y(e("select",{id:"vram-select","onUpdate:modelValue":a[1]||(a[1]=t=>d.value=t)},[(c(),v(M,null,w(P,t=>e("option",{key:t,value:t},m(t),9,V)),64))],512),[[S,d.value,void 0,{number:!0}]])])]),e("div",A,[a[4]||(a[4]=e("strong",null,"Recommended model:",-1)),e("span",{class:B(["model-name",O.value]),style:C({backgroundColor:n.value.bg,color:n.value.color})},m(n.value.model),7)])],2),a[8]||(a[8]=k('<blockquote data-v-a76ae127><p data-v-a76ae127><strong data-v-a76ae127>“Not recommended” means unreliable narrative output</strong> If the selector returns “Not recommended,” your system likely lacks the resources to run even the smallest narrative-tuned model effectively. In such cases, stories may suffer from <strong data-v-a76ae127>incoherent plot shifts</strong>, <strong data-v-a76ae127>flat characters</strong>, or <strong data-v-a76ae127>repetitive phrasing</strong>—often worse than drafting manually.</p></blockquote><hr data-v-a76ae127><h2 id="how-to-use-narrative-tuned-models-for-storywriting" tabindex="-1" data-v-a76ae127>How to Use Narrative-Tuned Models for Storywriting <a class="header-anchor" href="#how-to-use-narrative-tuned-models-for-storywriting" aria-label="Permalink to “How to Use Narrative-Tuned Models for Storywriting”" data-v-a76ae127>​</a></h2><p data-v-a76ae127>These models are designed for <strong data-v-a76ae127>long-form creative expression</strong>, not factual QA or code generation. Follow these guidelines to maximize emotional depth, stylistic control, and narrative consistency.</p><h3 id="_1-quantization-style-trade-offs" tabindex="-1" data-v-a76ae127>1. <strong data-v-a76ae127>Quantization &amp; Style Trade-offs</strong> <a class="header-anchor" href="#_1-quantization-style-trade-offs" aria-label="Permalink to “1. Quantization &amp; Style Trade-offs”" data-v-a76ae127>​</a></h3><table tabindex="0" data-v-a76ae127><thead data-v-a76ae127><tr data-v-a76ae127><th data-v-a76ae127>Quant</th><th data-v-a76ae127>Use Case</th><th data-v-a76ae127>Creative Impact</th></tr></thead><tbody data-v-a76ae127><tr data-v-a76ae127><td data-v-a76ae127><code data-v-a76ae127>bf16</code> / <code data-v-a76ae127>f16</code></td><td data-v-a76ae127>Literary nuance, poetic rhythm, complex metaphors</td><td data-v-a76ae127>Best for lyrical prose, experimental fiction, or deep POV</td></tr><tr data-v-a76ae127><td data-v-a76ae127><code data-v-a76ae127>q8</code></td><td data-v-a76ae127>Balanced fluency</td><td data-v-a76ae127>Ideal for most genres (fantasy, sci-fi, romance) with strong pacing</td></tr><tr data-v-a76ae127><td data-v-a76ae127><code data-v-a76ae127>q6</code> / <code data-v-a76ae127>q4</code></td><td data-v-a76ae127>Low-resource systems</td><td data-v-a76ae127>May flatten emotional arcs or repeat phrases—use only when necessary</td></tr></tbody></table><blockquote data-v-a76ae127><p data-v-a76ae127>📝 <strong data-v-a76ae127>Tip</strong>: For dialogue-heavy scenes, <code data-v-a76ae127>q8</code> or higher preserves vocal distinctiveness better than <code data-v-a76ae127>q4</code>.</p></blockquote><h3 id="_2-full-gpu-offload-is-essential-for-long-context" tabindex="-1" data-v-a76ae127>2. <strong data-v-a76ae127>Full GPU Offload Is Essential for Long Context</strong> <a class="header-anchor" href="#_2-full-gpu-offload-is-essential-for-long-context" aria-label="Permalink to “2. Full GPU Offload Is Essential for Long Context”" data-v-a76ae127>​</a></h3><ul data-v-a76ae127><li data-v-a76ae127><strong data-v-a76ae127>Narrative context lives in VRAM</strong>—always enable <strong data-v-a76ae127>full GPU offload</strong> (e.g., 48/48 layers).</li><li data-v-a76ae127>This ensures the model can reference earlier plot points, character traits, or worldbuilding details without slowing down.</li></ul><h3 id="_3-prompt-with-worldbuilding-voice-cues" tabindex="-1" data-v-a76ae127>3. <strong data-v-a76ae127>Prompt with Worldbuilding &amp; Voice Cues</strong> <a class="header-anchor" href="#_3-prompt-with-worldbuilding-voice-cues" aria-label="Permalink to “3. Prompt with Worldbuilding &amp; Voice Cues”" data-v-a76ae127>​</a></h3><p data-v-a76ae127>Creative models respond best to <strong data-v-a76ae127>rich, sensory prompts</strong>:</p><ul data-v-a76ae127><li data-v-a76ae127><p data-v-a76ae127>❌ <em data-v-a76ae127>“Write a fantasy story.”</em></p></li><li data-v-a76ae127><p data-v-a76ae127>✅ <em data-v-a76ae127>“Write a 500-word scene where a disillusioned clockwork mage in a steampunk city discovers her automaton companion has developed emotions. Use close third-person POV, melancholic tone, and include tactile details (oil, brass, rain).”</em></p></li><li data-v-a76ae127><p data-v-a76ae127>Include:</p><ul data-v-a76ae127><li data-v-a76ae127>Genre &amp; subgenre (e.g., “cozy fantasy,” “cyberpunk noir”)</li><li data-v-a76ae127>Character backstory or emotional state</li><li data-v-a76ae127>Desired pacing (e.g., “slow-burn tension,” “rapid action sequence”)</li><li data-v-a76ae127>Stylistic references (e.g., “like Neil Gaiman meets Becky Chambers”)</li></ul><blockquote data-v-a76ae127><p data-v-a76ae127>**For additional resources, check out <a href="https://sillytavernai.com/" target="_blank" rel="noreferrer" data-v-a76ae127>SillyTavernAI</a> and their community.</p></blockquote></li></ul><h3 id="_4-avoid-none-configurations" tabindex="-1" data-v-a76ae127>4. <strong data-v-a76ae127>Avoid “None” Configurations</strong> <a class="header-anchor" href="#_4-avoid-none-configurations" aria-label="Permalink to “4. Avoid “None” Configurations”" data-v-a76ae127>​</a></h3><ul data-v-a76ae127><li data-v-a76ae127>If your hardware yields <strong data-v-a76ae127>“none”</strong>, do <strong data-v-a76ae127>not</strong> force a model load via heavy CPU offloading.</li><li data-v-a76ae127>You&#39;ll get <strong data-v-a76ae127>incoherent timelines</strong>, <strong data-v-a76ae127>OOC (out-of-character) dialogue</strong>, or <strong data-v-a76ae127>generic tropes</strong>—worse than writing unassisted.</li><li data-v-a76ae127>Alternatives: <ul data-v-a76ae127><li data-v-a76ae127>Use cloud inference (e.g., <a href="https://aistudio.google.com/prompts/new_chat?model=gemma-3-27b-it" target="_blank" rel="noreferrer" data-v-a76ae127>aistudio.google.com</a> )</li><li data-v-a76ae127>Upgrade to ≥8 GB VRAM for basic story continuity</li></ul></li></ul><h3 id="_7-monitor-context-window-usage" tabindex="-1" data-v-a76ae127>7. <strong data-v-a76ae127>Monitor Context Window Usage</strong> <a class="header-anchor" href="#_7-monitor-context-window-usage" aria-label="Permalink to “7. Monitor Context Window Usage”" data-v-a76ae127>​</a></h3><ul data-v-a76ae127><li data-v-a76ae127>Creative writing benefits from <strong data-v-a76ae127>long context</strong> (16K+ tokens) to maintain continuity.</li><li data-v-a76ae127>If VRAM usage exceeds 90%, consider: <ul data-v-a76ae127><li data-v-a76ae127>Reducing context length (but risk losing plot threads)</li><li data-v-a76ae127>Switching to a lower quant (e.g., <code data-v-a76ae127>bf16</code> → <code data-v-a76ae127>q8</code>)</li><li data-v-a76ae127>Using <strong data-v-a76ae127>chunked generation</strong> (write scene-by-scene with memory prompts)</li></ul></li></ul><hr data-v-a76ae127><p data-v-a76ae127>By aligning your hardware, model choice, and prompt design with these principles, you&#39;ll unlock <strong data-v-a76ae127>emotionally resonant, stylistically rich storytelling</strong>—whether you&#39;re drafting a novel, exploring alternate universes, or breathing life into original characters.</p>',18))]))}}),L=_(z,[["__scopeId","data-v-a76ae127"]]);export{F as __pageData,L as default};
