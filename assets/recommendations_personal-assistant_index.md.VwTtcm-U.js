import{M as t}from"./chunks/ModelSelector.D8SPEWO0.js";import{c as n,o as s,af as r,J as i}from"./chunks/framework.CuQK53I8.js";const d=JSON.parse('{"title":"Personal Assistant","description":"","frontmatter":{"title":"Personal Assistant"},"headers":[],"relativePath":"recommendations/personal-assistant/index.md","filePath":"recommendations/personal-assistant/index.md"}'),o={name:"recommendations/personal-assistant/index.md"},c=Object.assign(o,{setup(m){const e=[{ramMin:128,vramMin:32,models:[{"GPT OSS 120B":{parameters:120,quantization:"MXFP4"}},{"Qwen3 30B Instruct 2507":{parameters:30,quantization:"BF16"}},{"Mistral Small 3.2":{parameters:24,quantization:"Q8_K_XL"}}],usefulness:1},{ramMin:128,vramMin:24,models:[{"GPT OSS 120B":{parameters:120,quantization:"MXFP4"}},{"Qwen3 30B Instruct 2507":{parameters:30,quantization:"BF16"}},{"Mistral Small 3.2":{parameters:24,quantization:"Q6_K_XL"}}],usefulness:.9},{ramMin:128,vramMin:0,models:[{"GPT OSS 120B":{parameters:120,quantization:"MXFP4"}},{"Qwen3 30B Instruct 2507":{parameters:30,quantization:"BF16"}}],usefulness:.8},{ramMin:64,vramMin:24,models:[{"GPT OSS 20B":{parameters:20,quantization:"MXFP4"}},{"Qwen3 30B Instruct 2507":{parameters:30,quantization:"BF16"}}],usefulness:.8},{ramMin:64,vramMin:0,models:[{"GPT OSS 20B":{parameters:20,quantization:"MXFP4"}},{"Qwen3 30B Instruct 2507":{parameters:30,quantization:"Q8_K_XL"}}],usefulness:.6},{ramMin:32,vramMin:24,models:[{"GPT OSS 20B":{parameters:20,quantization:"MXFP4"}},{"Gemma 3 27B":{parameters:27,quantization:"Q4_K_XL"}}],usefulness:.7},{ramMin:32,vramMin:8,models:[{"GPT OSS 20B":{parameters:20,quantization:"MXFP4"}},{"Gemma 3 12B":{parameters:12,quantization:"Q6_K_XL"}}],usefulness:.5},{ramMin:32,vramMin:0,models:[{"GPT OSS 20B":{parameters:20,quantization:"MXFP4"}}],usefulness:.4},{ramMin:16,vramMin:32,models:[{"GPT OSS 20B":{parameters:20,quantization:"MXFP4"}},{"Gemma 3 27B":{parameters:27,quantization:"Q8_K_XL"}}],usefulness:.6},{ramMin:16,vramMin:24,models:[{"GPT OSS 20B":{parameters:20,quantization:"MXFP4"}},{"Gemma 3 27B":{parameters:27,quantization:"Q4_K_XL"}}],usefulness:.5},{ramMin:16,vramMin:12,models:[{"GPT OSS 20B":{parameters:20,quantization:"MXFP4"}}],usefulness:.4},{ramMin:16,vramMin:8,models:[{"Gemma 3 12B":{parameters:12,quantization:"Q4_K_XL"}}],usefulness:.3},{ramMin:16,vramMin:4,models:[{"Qwen3 4B Instruct 2507":{parameters:4,quantization:"Q4_K_XL"}}],usefulness:.2}];return(l,a)=>(s(),n("div",null,[a[0]||(a[0]=r('<h1 id="personal-assistant-use-case" tabindex="-1">Personal Assistant Use Case <a class="header-anchor" href="#personal-assistant-use-case" aria-label="Permalink to “Personal Assistant Use Case”">​</a></h1><p>Recommendations for models that excel at memory, context retention, and personalized interactions.</p><blockquote><p>💡 <strong>Note</strong>: For personal assistant tasks—such as recalling preferences, maintaining conversation history, managing schedules, or adapting tone over time—<strong>instruct-tuned models with strong long-context handling</strong> are preferred over thinking-tuned variants. These models prioritize coherence, empathy, and user-specific adaptation over raw analytical power.</p></blockquote><p>Use the selector below to find the best <strong>assistant-like</strong> model for your hardware:</p>',4)),i(t,{modelDefinitions:e})]))}});export{d as __pageData,c as default};
